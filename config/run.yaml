## Dataset arguments
train_path: atm/data/test/pollution_1.csv
# if test_path is not supplied, train_path is assumed to point to train/test data
test_path: 
data_description: "Example dataset description"
class_column: class

## Datarun arguments
dataset_id: 
## the method to search from
methods: 
    - rf        # random forest
    - logreg    # logistic regression
    - dt        # decision tree
    - knn       #
    - svm       # 
    - mlp       # multiple layer percepton
    - gp        # gaussian process
    - gnb       # gaussian naive bayes
    - mnb       # multinomial naive bayes

# priority (higher number is more important)
priority: 1
# Should there be a classifier or walltime budget?
budget_type: classifier
# If budget_type is classifier, how many classifiers to try?
budget: 500
# How should ATM sample hyperparameters from a given frozen set?
tuner: gp
# r_minimum is the number of random runs performed in each hyperpartition before 
# allowing bayesian opt to select parameters.
r_minimum: 2
# gridding determines whether or not sample selection will happen on a grid. 
gridding: 0
# How should ATM select a particular hyperpartition (frozen set) from the 
# set of all hyperpartitions? 
selector: bestk
# k is number that xxx_k methods use. It is similar to r_minimum, except it
# determines how much "history" ATM considers for certain hyperpartition
# selection logic.
k_window: 5
# Which field to use for judgment of performance
# options: f1, roc_auc, accuracy
metric: f1
# Which data to use for computing judgment score
# cv = Cross_Validated performance on training data
# test = Performance on test data
score_target: cv
